{
 "cells": [
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 4,

=======
   "execution_count": 6,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime as dt\n",
    "import pytz\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report, log_loss, roc_curve, auc\n",
    "\n",
    "# for plotting figures in notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#opens the raw dataset and formats it into a list of dictionaries\n",
    "with open(\"conv_cal_20150801_hour_time_Mon15.vwin\", \"r\") as infile:\n",
    "    initial_data = []\n",
    "    label_list = []\n",
    "    for line in infile:\n",
    "        if line == \"\\n\":\n",
    "            continue\n",
    "        label = line.split()[0]\n",
    "        if label == '-1.0':\n",
    "            label = 0\n",
    "        if label == '1.0':\n",
    "            label = 1\n",
    "        label_list.append(label)\n",
    "        tmp = {}\n",
    "        tmp.update({item[0]: item[2:].rstrip() for item in line.split(\"|\")[1:]})\n",
    "        if tmp.get(\"t\"):\n",
    "            tmp[\"t\"] = tmp[\"t\"]\n",
    "        initial_data.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 18,

=======
   "execution_count": 3,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#random.shuffle(initial_data)\n",
    "from sklearn.utils import shuffle\n",
    "data, labels = shuffle(initial_data, label_list)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 6,

=======
   "execution_count": 4,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns value if key exists, and \" \" if not. Takes searched key and dictionary as input.\n",
    "def getit(item, store):\n",
    "    if item in store:\n",
    "        return store.get(item)\n",
    "    else:\n",
    "        return \" \""
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 53,

=======
   "execution_count": null,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#takes the formated dataset and creates a new list of dictionaries with the following feature interations:\n",
    "# -q si -q pi -q mi -q ai -q ps -q ei -q ri -q pc -q pb -q bi -q ki -q pk -q wi\n",
    "data_feature_interaction = []\n",
    "for line in data:\n",
    "    temp_dict = line.copy()\n",
    "    tmp = {\n",
    "        \"si\": getit(\"s\", line) + \" \" + getit(\"i\", line),\n",
    "        \"pi\": getit(\"p\", line) + \" \" + getit(\"i\", line),\n",
    "        \"mi\": getit(\"m\", line) + \" \" + getit(\"i\", line),\n",
    "        \"ai\": getit(\"a\", line) + \" \" + getit(\"i\", line),\n",
    "        \"ps\": getit(\"p\", line) + \" \" + getit(\"s\", line),\n",
    "        \"ei\": getit(\"e\", line) + \" \" + getit(\"i\", line),\n",
    "        \"ri\": getit(\"r\", line) + \" \" + getit(\"i\", line),\n",
    "        \"pc\": getit(\"p\", line) + \" \" + getit(\"c\", line),\n",
    "        \"pb\": getit(\"p\", line) + \" \" + getit(\"b\", line),\n",
    "        \"bi\": getit(\"b\", line) + \" \" + getit(\"i\", line),\n",
    "        \"ki\": getit(\"k\", line) + \" \" + getit(\"i\", line),\n",
    "        \"pk\": getit(\"p\", line) + \" \" + getit(\"k\", line),\n",
    "        \"wi\": getit(\"w\", line) + \" \" + getit(\"i\", line),\n",
    "    }\n",
    "    temp_dict.update(tmp)\n",
    "    data_feature_interaction.append(temp_dict)\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 44,

=======
   "execution_count": 34,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD

    "N = 10000\n",
    "Y = np.array(labels[:N])\n",
    "#feat = data_feature_interaction[:N]\n",
    "feat = data[:N]"

=======
    "N = 50000\n",
    "M = int(N * 0.8)\n",
    "Y = np.array(labels[:N])\n",
    "#feat = data_feature_interaction[:N]\n",
    "feat = data[:N]"
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 61,
   "metadata": {
    "collapsed": true

=======
   "execution_count": 35,
   "metadata": {
    "collapsed": false
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   },
   "outputs": [],
   "source": [
    "v = DictVectorizer(sparse=True)\n",
    "\n",
<<<<<<< HEAD

    "X = v.fit_transform(data_feature_interaction)\n",

=======
    "X = v.fit_transform(feat)\n",
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
    "feature_names = {name: index for name, index in v.vocabulary_.items()}\n",
    "vec_X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 62,

=======
   "execution_count": 37,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "X_train, Y_train = vec_X[:9000], Y[:9000]\n",
    "X_test, Y_test = vec_X[9000:], Y[9000:]"
=======
    "X_train, Y_train = vec_X[:M], Y[:M]\n",
    "X_test, Y_test = vec_X[M:], Y[M:]"
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 63,

   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [

       "65189"
      ]
     },
     "execution_count": 63,

     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test[0])"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 64,

=======
   "execution_count": 38,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# logistic regression baseline\n",
    "lr_model = LogisticRegression(penalty='l2')\n",
    "lr = lr_model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 65,

=======
   "execution_count": 40,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "y_prob = lr.predict_proba(X_test)\n",
    "cm = confusion_matrix(Y_test, y_pred)\n",
    "cr = classification_report(Y_test, y_pred)\n",
    "ll = log_loss(Y_test, y_prob)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, y_prob[:, 1])\n",
<<<<<<< HEAD

    "roc_auc = auc(fpr, tpr)"

=======
    "#auc = auc(fpr, tpr)"
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 66,


=======
   "execution_count": 41,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
<<<<<<< HEAD

      "          0       0.88      0.99      0.93       881\n",
      "          1       0.09      0.01      0.02       119\n",
      "\n",
      "avg / total       0.79      0.87      0.82      1000\n",

=======
      "          0       0.95      0.97      0.96      8648\n",
      "          1       0.76      0.64      0.70      1352\n",
      "\n",
      "avg / total       0.92      0.92      0.92     10000\n",
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
      "\n"
     ]
    }
   ],
   "source": [
    "print cr"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 52,

=======
   "execution_count": 42,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": false
   },
   "outputs": [
<<<<<<< HEAD

     "data": {
      "text/plain": [
       "0.41001808580583099"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll"

=======
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.191099582698\n"
     ]
    }
   ],
   "source": [
    "print ll, #auc"
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 69,

=======
   "execution_count": null,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
<<<<<<< HEAD
    "# random forest\n",
    "\n",

    "ensemble_model = RandomForestClassifier(n_estimators=10)\n",

=======
    "def select_predictive_features(X, labels, feature_names, n_estimators, top_percentage):\n",
    "    clf_rf = RandomForestClassifier(max_features=10, max_depth=10, n_estimators=n_estimators, n_jobs=1)\n",
    "\n",
    "    clf_rf.fit(X, labels)\n",
    "    importances = clf_rf.feature_importances_\n",
    "    sorted_indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    if top_percentage:\n",
    "        rf_selected_indices = sorted_indices[: int(len(sorted_indices)*top_percentage)]\n",
    "    else:\n",
    "        rf_selected_indices = []\n",
    "        for index, importance in enumerate(importances):\n",
    "            if importance != 0.0:\n",
    "                rf_selected_indices.append(index)\n",
    "\n",
    "    final_features = {name: index for name, index in feature_names.items() if\n",
    "                      index in rf_selected_indices}\n",
    "\n",
    "    return final_features\n",
    "\n",
    "\n",
    "def select_features(X, labels, feature_dict, top_percentage=0.8, n_estimators=10):\n",
    "\n",
    "    feature_names = select_predictive_features(X, labels, feature_dict, n_estimators, top_percentage)\n",
    "    X = X[:, feature_names.values()]\n",
    "\n",
    "    return feature_names, X, labels\n",
    "\n",
    "s_features, s_X, s_Y = select_features(vec_X, Y, feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s_Y = s_labels\n",
    "X_train, Y_train = s_X[:M], s_Y[:M]\n",
    "X_test, Y_test = s_vec_X[M:], s_Y[M:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# random forest\n",
    "ensemble_model = RandomForestClassifier(n_estimators=100)\n",
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
    "ensemble = ensemble_model.fit(X_train, Y_train)\n",
    "en_pred = ensemble.predict(X_test)\n",
    "en_prob = ensemble.predict_proba(X_test) "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(Y_test, en_pred)\n",
    "cr = classification_report(Y_test, en_pred)\n",
    "ll = log_loss(Y_test, en_prob)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test, en_prob[:, 1])\n",
    "roc_auc = auc(fpr, tpr)"

=======
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-b45eb60eef1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0men_ll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0men_fpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_tpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0men_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_fpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0men_tpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "en_cm = confusion_matrix(Y_test, en_pred)\n",
    "en_cr = classification_report(Y_test, en_pred)\n",
    "en_ll = log_loss(Y_test, en_prob)\n",
    "en_fpr, en_tpr, thresholds = roc_curve(Y_test, en_prob[:, 1])\n",
    "#en_auc = auc(en_fpr, en_tpr)"
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD

   "execution_count": 71,

=======
   "execution_count": 45,
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
<<<<<<< HEAD

      "          0       0.88      0.99      0.93       881\n",
      "          1       0.11      0.01      0.02       119\n",
      "\n",
      "avg / total       0.79      0.87      0.82      1000\n",
      "\n"

=======
      "          0       0.95      0.97      0.96      8648\n",
      "          1       0.79      0.64      0.71      1352\n",
      "\n",
      "avg / total       0.93      0.93      0.93     10000\n",
      "\n",
      "0.223261177824\n"
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
     ]
    }
   ],
   "source": [
<<<<<<< HEAD

    "print cr"
=======
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
    "print en_cr\n",
    "print en_ll, #en_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.learning_curve import learning_curve, validation_curve\n",
    "from sklearn import cross_validation\n",
    "\n",
    "def make_plot(x_axis, train_scores, test_scores, metric, log=False):\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "    plt.fill_between(x_axis, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(x_axis, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1,\n",
    "                     color='g')\n",
    "\n",
    "    if not log:\n",
    "        plt.plot(x_axis, train_scores_mean, \"o-\", color=\"r\",\n",
    "                 label=\"Training {} score\".format(metric))\n",
    "        plt.plot(x_axis, test_scores_mean, \"o-\", color=\"g\",\n",
    "                 label=\"Validation {} scores\".format(metric))\n",
    "    else:\n",
    "        plt.semilogx(x_axis, train_scores_mean, \"o-\", color=\"r\",\n",
    "                     label=\"Training {} score\".format(metric))\n",
    "        plt.semilogx(x_axis, test_scores_mean, \"o-\", color=\"g\",\n",
    "                     label=\"Validation {} scores\".format(metric))\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "def plot_learning_curves(estimator, title, X, y, ylim=None, metric=None, n_jobs=3,\n",
    "                         train_sizes=np.linspace(0.5, 1.0, 5)):\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    cv = cross_validation.StratifiedKFold(y, n_folds=5)\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, X, y, cv=cv,\n",
    "                                                            n_jobs=n_jobs,\n",
    "                                                            train_sizes=train_sizes,\n",
    "                                                            scoring=metric)\n",
    "\n",
    "    return make_plot(train_sizes, train_scores, test_scores, metric)\n",
    "\n",
    "\n",
    "def generate_learning_curves(estimator, predictors, labels):\n",
    "    list_metric = [\"accuracy\", \"precision\", \"recall\"]\n",
    "    for metric in list_metric:\n",
    "        title = \"{} Learning Curves\".format(metric.title())\n",
    "        lc_plot = plot_learning_curves(estimator, title, predictors, labels, metric=metric,\n",
    "                                       n_jobs=3)\n",
    "\n",
    "        curve_name = \"learning_curves\"\n",
    "        pp = PdfPages(\"{}.pdf\".format(title))\n",
    "        lc_plot.savefig(pp, format='pdf')\n",
    "        pp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generate_learning_curves(lr_model, X_train, Y_train)"
<<<<<<< HEAD

=======
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
<<<<<<< HEAD

=======
>>>>>>> 8218c31e9b31117b3dd0d48a0e45db85d9c9d09f
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
